================================================================================
          MODERN ANALYTICS & AI HUB: THE ULTIMATE DEMO GUIDE
================================================================================

This is a comprehensive, step-by-step script for demonstrating the full power of 
the Modern Analytics & AI Hub. It is designed to "show off" the system's 
capabilities, moving from descriptive analytics to advanced AI and self-healing 
data pipelines.

--------------------------------------------------------------------------------
PHASE 1: ENVIRONMENT SETUP
--------------------------------------------------------------------------------

1.  **Install Dependencies & Drivers**
    Open your terminal in the project root and run:
    > pip install pandas sqlalchemy pyodbc openai plotly streamlit scipy scikit-learn faker
    *Ensure you have the ODBC Driver 17 for SQL Server installed.*

2.  **Configure Environment Variables**
    Create or edit the `.env` file in the project root:
    - DB_SERVER=...
    - DB_DATABASE=...
    - DB_USERNAME=...
    - DB_PASSWORD=...
    - OPENAI_API_KEY=sk-... (Crucial for Text-to-SQL, Semantic Search, and Vision)

3.  **Generate the "Perfect" Demo Data**
    Run the setup script. This doesn't just create tables; it injects specific
    statistical patterns, anomalies, and text correlations that the AI is 
    programmed to find later.
    > python scripts/setup_demo_environment.py
    
    *Check Output*: Look for "ğŸ‰ Demo Environment Setup Complete!".

--------------------------------------------------------------------------------
PHASE 2: GENERATE AI INSIGHTS (BATCH LAYER)
--------------------------------------------------------------------------------

Before the demo, we need the "Batch AI" to process history, train models, and 
detect the anomalies we injected.

1.  Start Dagster:
    > dagster dev

2.  Open the Dagster UI (http://localhost:3000).
3.  Locate the asset group `analytics_ai` (or search for `run_predictive_analytics`).
4.  Click **Materialize** on the `run_predictive_analytics` asset.
    *   *Behind the Scenes*: The system pulls the last year of data, trains an 
        Isolation Forest model to find outliers, runs a Prophet forecast for the 
        next 30 days, and saves all predictions to the SQL database.

--------------------------------------------------------------------------------
PHASE 3: THE "SHOW OFF" DEMO SCRIPT (UI LAYER)
--------------------------------------------------------------------------------

Launch the Analytics UI in a new terminal:
> streamlit run analytics_ui.py

**Login**: Username: `admin` / Password: `admin123`

================================================================================
SCENARIO 1: THE EXECUTIVE OVERVIEW (Generative AI / LLM)
================================================================================
*Goal: Show that the system understands data context without human input.*

1.  **Navigate to "Dashboard"**.
2.  **Point out the Metrics**:
    - "AI Detected Anomalies": Point out the red number (e.g., 5).
    - "Failed Runs": Point out the system health.
3.  **The "Wow" Factor**: Scroll to **Automated Data Story**.
    - *Action*: Read the first bullet point aloud.
    - *Talking Point*: "I didn't write this report. A Generative AI (LLM) agent analyzed the raw pipeline logs and anomaly tables to generate this executive summary in real-time."
    - *Code Reference*:
        - UI: `analytics_ui.py` (Lines ~112-117)
        - Logic: `ml_engine.py` (Lines ~198-226, `generate_data_story`)

================================================================================
SCENARIO 2: CONVERSATIONAL ANALYTICS (LLM-Powered Text-to-SQL)
================================================================================
*Goal: Show democratization of data access.*

1.  **Navigate to "Conversational Analytics"**.
2.  **The Query**: Type: `Show me total sales by region for last month`
3.  **The Result**:
    - Show the generated SQL code block (proving transparency/security).
    - Show the resulting data table.
    - *Talking Point*: "This uses an LLM to translate natural language into SQL. It understands 'last month' and 'sales', writes valid SQL, checks it for safety, and executes it."
    - *Code Reference*:
        - UI: `analytics_ui.py` (Lines ~153-167)
        - Logic: `ml_engine.py` (Lines ~238-257, `generate_sql_from_question`)

================================================================================
SCENARIO 3: AGENTIC ANALYST (Autonomous AI Agent)
================================================================================
*Goal: Show the AI planning and executing a complex task autonomously.*

1.  **Navigate to "Agentic Analyst"**.
2.  **The Goal**: Enter a high-level goal:
    `Analyze the sales trend for the last 3 months, identify any significant drops, and check customer feedback for those periods to explain why.`
3.  **Action**: Click **Launch Agent**.
4.  **The Reveal**:
    - **Planning (Chain-of-Thought)**: Show the "Agent is planning..." expander. It breaks the goal into steps (Data Retrieval -> Analysis).
        - *Learning Point*: This simulates "Chain of Thought" reasoning, where the LLM breaks a complex problem into sub-tasks before acting.
    - **Execution (Tool Use)**:
        - **Tool 1 (SQL Generator)**: It generates SQL to get sales data.
        - **Tool 2 (Data Analyzer)**: It calculates metrics from the retrieved dataframe.
        - **Tool 3 (Storyteller)**: It generates a final report explaining the drop (referencing the "server error" feedback injected in the demo data).
    - *Talking Point*: "This isn't just a chatbot. It's an agent. It formulated a plan, queried the database, found the anomaly, and then correlated it with customer feedback to give me a complete answer."
    - *Code Reference*:
        - UI Implementation: `analytics_ui.py` (Lines ~185-246)
            - *Planning Simulation*: Lines ~201-207
            - *Context Retrieval*: Lines ~212-214
            - *Tool Execution*: Lines ~217-240
        - AI Logic: `ml_engine.py`
            - *Text-to-SQL Tool*: Lines ~238-257 (`generate_sql_from_question`)
            - *Insight Generator Tool*: Lines ~198-226 (`generate_data_story`)

================================================================================
SCENARIO 4: DIAGNOSTIC AI (Root Cause Analysis)
================================================================================
*Goal: Solve a business mystery in seconds.*

1.  **Navigate to "Root Cause Analysis"**.
2.  **Setup**:
    - Table: `fact_retail_sales`
    - Metric: `SalesAmount`
    - Target Date: Select the date **3 days ago** (The setup script injected a 80% drop here).
3.  **Action**: Click **Analyze Drivers**.
4.  **The Reveal**:
    - The system will display `Region = North` and `Category = Electronics` with a large negative impact (e.g., -80%).
    - *Talking Point*: "Usually, an analyst would spend hours slicing data in Excel to find this. The AI scanned every combination of dimensions and found the exact source of the crash: Electronics in the North region."
    - *Code Reference*:
        - UI: `analytics_ui.py` (Lines ~261)
        - Logic: `ml_engine.py` (Lines ~60-115, `analyze_root_cause`)

================================================================================
SCENARIO 5: SEMANTIC INTELLIGENCE (LLM RAG / Vector Search)
================================================================================
*Goal: Connect the quantitative drop to qualitative feedback.*

1.  **Navigate to "Semantic Search"**.
2.  **Context**: "We know sales dropped in North/Electronics. Was it a pricing issue? A product issue?"
3.  **Setup**:
    - Table: `fact_retail_sales`
    - Column: `CustomerFeedback`
    - Query: `technical issues during checkout`
4.  **Action**: Click **Search**.
5.  **The Reveal**:
    - The results show rows containing: *"Cannot checkout, server error"*.
    - *Crucial Point*: Note that the word "technical" might not appear in the result.
    - *Talking Point*: "This uses LLM Embeddings for Semantic Search. I searched for 'technical issues', and it found 'server error' because the LLM understands they mean the same thing. Traditional keyword search would have failed here."
    - *Code Reference*:
        - UI: `analytics_ui.py` (Lines ~351)
        - Logic: `ml_engine.py` (Lines ~359-395, `perform_semantic_search`)

================================================================================
SCENARIO 6: PRESCRIPTIVE ANALYTICS (Optimization)
================================================================================
*Goal: Move from "What happened?" to "What should we do?".*

1.  **Navigate to "Prescriptive Optimization"**.
2.  **Context**: "We need to recover that lost revenue next week. How much should we spend on ads?"
3.  **Setup**:
    - Table: `fact_retail_sales`
    - Target: `SalesAmount`
    - Inputs: Select `MarketingSpend` and `DiscountRate`.
4.  **Action**: Click **Run Optimization**.
5.  **The Reveal**:
    - The system displays a "Projected Maximum Target".
    - It gives specific recommendations: e.g., *MarketingSpend: $840.50*, *DiscountRate: 0.15*.
    - *Talking Point*: "The system modeled the elasticity of demand based on our history and used a mathematical solver to give us the optimal marketing mix."
    - *Code Reference*:
        - UI: `analytics_ui.py` (Lines ~320)
        - Logic: `ml_engine.py` (Lines ~306-357, `optimize_business_objective`)

================================================================================
SCENARIO 7: MULTI-MODAL ANALYSIS (Vision LLM)
================================================================================
*Goal: Show the system handling unstructured, non-text data.*

1.  **Navigate to "Multi-Modal Analysis"**.
2.  **Context**: "We just received a vendor invoice as a scanned image."
3.  **Action**:
    - Upload a sample image (e.g., a screenshot of an invoice or a receipt).
    - In "Fields to Extract", type: `Invoice Number, Total Amount, Vendor Name, Date`.
    - Click **Extract Data**.
4.  **The Reveal**:
    - The JSON result appears with the correct data extracted from the pixels.
    - *Talking Point*: "We are using a Multi-Modal LLM (GPT-4 Vision) to turn pixels into structured database records instantly."
    - *Code Reference*:
        - UI: `analytics_ui.py` (Lines ~406)
        - Logic: `ml_engine.py` (Lines ~432-483, `extract_structured_data`)

================================================================================
SCENARIO 8: AUTONOMOUS DATA REPAIR (Self-Healing)
================================================================================
*Goal: Show AI maintaining data quality.*

1.  **Navigate to "Autonomous Data Repair"**.
2.  **Context**: "Data entry errors happen. Let's see if the AI can find them."
3.  **Setup**:
    - Table: `fact_retail_sales`
4.  **Action**: Click **Scan for Issues**.
5.  **The Reveal**:
    - The system should find the injected typo: `Issue: Potential typo 'Nrth'`, `Suggestion: 'North'`.
    - It shows the confidence level and affected row count.
    - *Action*: Click the checkbox to select the fix, then click **Apply Selected Fixes**.
    - *Talking Point*: "The system uses fuzzy matching logic to identify inconsistencies. It doesn't just flag them; it generates the SQL `UPDATE` statement to fix them with one click."
    - *Code Reference*:
        - UI: `analytics_ui.py` (Lines ~371)
        - Logic: `ml_engine.py` (Lines ~397-430, `suggest_data_repairs`)

================================================================================
SCENARIO 9: AI AUTO-DASHBOARDS (Instant Viz)
================================================================================
*Goal: Zero-effort visualization.*

1.  **Navigate to "AI Auto-Dashboards"**.
2.  **Setup**: Select `fact_retail_sales`.
3.  **The Reveal**:
    - The system automatically detects the Date column and the Sales column.
    - It renders a Time Series chart without you asking for it.
    - *Talking Point*: "I didn't configure a chart type. The AI analyzed the schema, saw a date and a float, and decided a Time Series was the best way to visualize this data."
    - *Code Reference*:
        - UI: `analytics_ui.py` (Lines ~468)
        - Logic: `ml_engine.py` (Lines ~259-304, `recommend_visualization`)

================================================================================
SCENARIO 10: WHAT-IF SIMULATOR
================================================================================
*Goal: Strategic planning.*

1.  **Navigate to "What-If Simulator"**.
2.  **Action**:
    - Move the "Marketing Spend Increase" slider to +20%.
    - Move "Pricing Adjustment" to -5%.
3.  **The Reveal**:
    - The "Projected Revenue" number updates instantly.
    - The chart shows the "Simulated Scenario" diverging from the "Baseline".
    - *Talking Point*: "This allows business stakeholders to play with variables and see the potential financial impact in real-time."
    - *Code Reference*:
        - UI: `analytics_ui.py` (Lines ~440-450)
        - Logic: Inline simulation logic in `analytics_ui.py`.

================================================================================
SCENARIO 11: PREDICTIVE INSIGHTS (Forecasting)
================================================================================
*Goal: Looking forward.*

1.  **Navigate to "Predictive Insights"**.
2.  **Setup**: Select `fact_retail_sales`.
3.  **The Reveal**:
    - Show the historical line (solid).
    - Show the forecast line (dashed) extending into the future.
    - Point out any red dots (Anomalies).
4.  **Action**: Select a date in the "Anomaly Feedback" dropdown and click **Dismiss**.
    - *Talking Point*: "This is Human-in-the-Loop AI. By dismissing this, I'm retraining the model to ignore similar patterns in the future, reducing alert fatigue."
    - *Code Reference*:
        - UI: `analytics_ui.py` (Lines ~180-215)
        - Logic: `ml_engine.py` (Lines ~40-57 `detect_anomalies`, Lines ~134-165 `generate_forecast`)

================================================================================
SCENARIO 12: DATA GOVERNANCE (Quality Gates)
================================================================================
*Goal: Prove that the AI is trained on trusted data.*

1.  **Navigate to "Data Explorer"**.
2.  **Context**: "How do we know the data feeding these AI models is accurate? We have automated governance gates."
3.  **Action**:
    - Select Table: `data_quality_rules`.
    - Show the rules: e.g., `Sales_Not_Negative` (Severity: FAIL).
    - *Talking Point*: "We define rules as metadata. If 'Sales' is negative, the pipeline halts immediately."
4.  **Action**:
    - Select Table: `data_quality_run_logs`.
    - Sort by `check_timestamp` DESC.
    - Point to the row with `status = FAIL` and `failing_row_count = 12`.
    - *Talking Point*: "Look hereâ€”5 days ago, a bad file was uploaded with negative sales numbers. The system caught it, blocked the load, and alerted the team. No bad data reached the dashboard."
    - *Code Reference*:
        - Setup: `setup_demo_environment.py` (Lines ~180-210)
        - Logic: `02_setup_data_governance.sql` (Stored Procedure `sp_execute_data_quality_checks`)

================================================================================
SCENARIO 13: AUTOMATED ENRICHMENT
================================================================================
*Goal: Show how the system adds value to raw data automatically.*

1.  **Navigate to "Data Explorer"**.
2.  **Context**: "Raw data is often incomplete. For example, transactions might have a Product ID but missing the Category."
3.  **Action**:
    - Select Table: `data_enrichment_rules`.
    - Show the rule: `Enrich_Product_Category`.
    - *Talking Point*: "We don't write Python code to fix this. We just add a rule: 'If Category is missing, look it up in the Product Master table using the SKU'. The pipeline handles the join automatically."
    - *Code Reference*:
        - Setup: `setup_demo_environment.py` (Lines ~197-202)
        - Logic: `README.md` (Section: Automated Data Enrichment)

================================================================================
END OF DEMO
================================================================================

================================================================================
APPENDIX: DEEP DIVE TECHNICAL REFERENCE & LEARNING GUIDE
================================================================================
This section provides a technical deep-dive into the AI and Analytics concepts 
implemented in this framework. Use this to understand the "How" and "Why" behind 
the features.

Each section includes "Color Visualizations" (using Emojis and Layouts) to 
make the abstract concepts concrete.

--------------------------------------------------------------------------------
1. LARGE LANGUAGE MODELS (LLMs) & GENERATIVE AI
--------------------------------------------------------------------------------
*   **Technical Definition**: LLMs are probabilistic models based on the **Transformer** 
    architecture (specifically the Decoder-only stack in GPT models). They are trained 
    on vast corpora to predict the next token (sub-word unit) in a sequence.
*   **Mechanism**:
    1.  **Tokenization**: Input text is converted into numerical tokens.
    2.  **Embeddings**: Tokens are mapped to vectors in a high-dimensional space.
    3.  **Self-Attention**: The model weighs the importance of different words in the 
        context window relative to each other (e.g., linking "bank" to "river" vs "money").
    4.  **Probabilistic Output**: The model outputs a probability distribution (logits) 
        over the vocabulary for the next token.
*   **Key Parameters**:
    *   **Temperature**: Controls randomness. Low (0.1) makes the model deterministic 
        and focused (good for SQL/Code). High (0.8) makes it creative (good for stories).
    *   **Context Window**: The maximum number of tokens the model can process at once 
        (Input + Output).
*   **In this Demo**: Used in `generate_data_story` with a low temperature for factual 
    summarization of logs.

    **VISUALIZATION 1: THE LLM BRAIN ğŸ§ **
    *Caption: How an LLM turns text into numbers, "thinks", and predicts the next word.*
    
    [USER INPUT] "The cat sat"
          â¬‡ï¸
    ğŸ”¤ Tokenization:  [102] [554] [998]  (Converts words to IDs)
          â¬‡ï¸
    ğŸ”¢ Embeddings:    [0.1, -0.5, 0.8...] (Maps IDs to Vector Space)
          â¬‡ï¸
    ğŸ§  TRANSFORMER LAYERS (The "Neural Network")
       â”œâ”€â”€ ğŸ”´ Self-Attention (Understanding Context: "sat" relates to "cat")
       â”œâ”€â”€ ğŸŸ  Feed-Forward Networks (Accessing World Knowledge)
       â””â”€â”€ ğŸŸ¡ Normalization (Stabilizing the math)
          â¬‡ï¸
    ğŸ² Probabilities: ğŸŸ¦ "on" (80%) | â¬œ "in" (15%) | ğŸŸ¥ "up" (5%)
          â¬‡ï¸
    âœ¨ OUTPUT: "on"

--------------------------------------------------------------------------------
2. TEXT-TO-SQL
--------------------------------------------------------------------------------
*   **Concept**: A specialized application of LLMs where the output is constrained 
    to valid SQL syntax based on a provided schema.
*   **Architecture**:
    *   **Input**: User Question + Database Schema (DDL or list of columns).
    *   **System Prompt**: Instructions to act as a SQL expert, use specific dialects 
        (T-SQL), and avoid hallucinations.
    *   **Output**: Executable SQL string.
*   **Security & Governance (Critical)**:
    *   **Schema Only**: We NEVER send actual row data to the LLM, only metadata 
        (Table names, Column names, Types). This preserves data privacy.
    *   **Validation**: The generated SQL is parsed (using Regex or AST) to block 
        destructive commands (`DROP`, `DELETE`, `TRUNCATE`) before execution.
*   **Implementation**: `MLEngine.generate_sql_from_question`. It constructs a 
    prompt containing `INFORMATION_SCHEMA` data and enforces a read-only policy.

    **VISUALIZATION 2: THE TEXT-TO-SQL PIPELINE ğŸ”„**
    *Caption: The secure flow of data from a user question to a database result.*

    ğŸ‘¤ User: "Show sales for last month"
          â¬‡ï¸
    ğŸ¤– LLM Agent (Receives: Schema ğŸ—‚ï¸ + Question â“)
       (Note: No actual data rows are sent here, only table names!)
          â¬‡ï¸
    ğŸ“ Generates SQL: "SELECT sum(amount) FROM sales WHERE date > ..."
          â¬‡ï¸
    ğŸ›¡ï¸ Security Gate (The "Bouncer")
       â”œâ”€â”€ ğŸš« Checks for: DROP, DELETE, TRUNCATE
       â””â”€â”€ âœ… Status: SAFE
          â¬‡ï¸
    ğŸ›¢ï¸ Database Engine (Executes Query)
          â¬‡ï¸
    ğŸ“Š Result: [ $50,000 ] â¡ï¸ Displayed to User

--------------------------------------------------------------------------------
3. AGENTIC AI (Autonomous Agents)
--------------------------------------------------------------------------------
*   **Definition**: An Agent is an LLM loop equipped with **Tools** (functions) and 
    **Reasoning** capabilities (ReAct Pattern: Reason + Act).
*   **The ReAct Loop**:
    1.  **Thought**: The LLM analyzes the user goal and current state.
    2.  **Plan**: It determines the next step (e.g., "I need data").
    3.  **Action**: It selects a Tool (e.g., `run_sql_query`) and generates arguments.
    4.  **Observation**: The system executes the tool and feeds the output (DataFrame) 
        back to the LLM.
    5.  **Synthesis**: The LLM uses the observation to answer the user or plan the next step.
*   **Tools**: In our code, "Tools" are just Python functions wrapped in a way the 
    LLM can invoke (e.g., `generate_sql`, `generate_data_story`).
*   **Why it matters**: Standard LLMs are passive (Input -> Output). Agents are active; 
    they can perform multi-step workflows to solve open-ended problems.

    **VISUALIZATION 3: THE AGENTIC LOOP (ReAct) ğŸ”„**
    *Caption: How an autonomous agent thinks, plans, and acts to solve problems.*

    ğŸ¯ GOAL: "Analyze the sales drop"
          â¬‡ï¸
    ğŸ§  AGENT BRAIN (Thinking...)
       â”œâ”€â”€ ğŸ’­ THOUGHT: "I don't have the data yet."
       â”œâ”€â”€ ğŸ“‹ PLAN: "I need to query the database first."
       â””â”€â”€ ğŸ› ï¸ ACTION: Call Tool [SQL_Generator]
             â¬‡ï¸
          ğŸ”„ LOOP (The Agent waits for the tool)
             â¬‡ï¸
       ğŸ‘€ OBSERVATION: "Sales dropped 20% last week."
       â”œâ”€â”€ ğŸ’­ THOUGHT: "That's bad. I need to know why. Let's check feedback."
       â””â”€â”€ ğŸ› ï¸ ACTION: Call Tool [Semantic_Search]
             â¬‡ï¸
    ğŸ FINAL ANSWER: "Sales dropped due to a server outage reported in feedback."

--------------------------------------------------------------------------------
4. RAG (RETRIEVAL-AUGMENTED GENERATION) & VECTOR SEARCH
--------------------------------------------------------------------------------
*   **Problem**: LLMs have a knowledge cutoff and don't know your private data.
*   **Solution (RAG)**: Retrieve relevant private data and inject it into the LLM's 
    context window at query time.
*   **Vector Embeddings**:
    *   We use an Embedding Model (e.g., `text-embedding-3-small`) to convert text 
        into **Dense Vectors** (arrays of floating-point numbers, e.g., 1536 dimensions).
    *   **Semantic Meaning**: In this vector space, concepts that are semantically 
        similar ("Dog" and "Puppy", or "Error 500" and "Crash") are located close 
        together geometrically.
*   **Cosine Similarity**: The mathematical operation used to measure the distance 
    between two vectors. A score of 1.0 means identical meaning; 0 means unrelated.
*   **Implementation**: `MLEngine.perform_semantic_search` calculates the cosine 
    similarity between the User Query vector and the Database Row vectors.

    **VISUALIZATION 4: THE RAG ARCHITECTURE ğŸ“š**
    *Caption: Injecting private knowledge into the LLM using Vector Search.*

    â“ User Query: "Why did the server crash?"
          â¬‡ï¸
    ğŸ”¢ Embedding Model â¡ï¸ [0.9, 0.2, 0.5...] (Converts query to numbers)
          â¬‡ï¸
    ğŸ” Vector Database (Semantic Search)
       â”œâ”€â”€ ğŸ“„ Doc A: "Server Uptime 99%" (Distance: 0.8) âŒ
       â””â”€â”€ ğŸ“„ Doc B: "Error 500 Log"     (Distance: 0.1) âœ… MATCH!
          â¬‡ï¸
    ğŸ“¥ Context Injection
       Prompt: "Context: [Error 500 Log...] + Question: [Why crash?]"
          â¬‡ï¸
    ğŸ¤– LLM Response: "The logs indicate an Error 500 caused the crash."

--------------------------------------------------------------------------------
5. MULTI-MODAL AI
--------------------------------------------------------------------------------
*   **Definition**: Models capable of processing and correlating information from 
    multiple modalities (Text, Images, Audio).
*   **Vision Transformers (ViT)**:
    *   Images are sliced into patches (e.g., 16x16 pixels).
    *   These patches are flattened and linearly projected into embeddings, similar 
        to word tokens.
    *   The Transformer processes these visual tokens alongside text tokens.
*   **Use Case**: OCR on steroids. Instead of just reading text characters, the model 
    understands **layout** and **context** (e.g., distinguishing a "Total" field 
    from a "Subtotal" based on position and font weight).
*   **In this Demo**: We use GPT-4o to extract JSON from invoice images.

    **VISUALIZATION 5: VISION TRANSFORMER (ViT) ğŸ‘ï¸**
    *Caption: How AI reads an invoice image.*

    ğŸ–¼ï¸ IMAGE (Invoice.jpg)       ğŸ“ TEXT PROMPT ("Extract Total")
          â¬‡ï¸                            â¬‡ï¸
    ğŸ‘ï¸ Vision Encoder (Pixels)    ğŸ”¤ Text Encoder (Tokens)
          â†˜ï¸                    â†™ï¸
             ğŸ”— CROSS-ATTENTION LAYER
             (Aligns the word "Total" with the pixels showing "$500")
                      â¬‡ï¸
             âœ¨ JSON OUTPUT: { "total": 500.00 }

--------------------------------------------------------------------------------
6. PRESCRIPTIVE ANALYTICS & OPTIMIZATION
--------------------------------------------------------------------------------
*   **Hierarchy of Analytics**:
    1.  **Descriptive**: What happened? (Dashboards)
    2.  **Predictive**: What will happen? (Forecasting)
    3.  **Prescriptive**: How can we make it happen? (Optimization)
*   **Technical Implementation**:
    1.  **Digital Twin**: We train a regression model ($y = mx + b$) to approximate 
        the business process. This model predicts the Target (Sales) based on Inputs 
        (Marketing Spend, Price).
    2.  **Objective Function**: We define a mathematical function to maximize (Profit) 
        or minimize (Cost).
    3.  **Solver**: We use `scipy.optimize.minimize` (SLSQP algorithm) to mathematically 
        find the input values that yield the best output, subject to constraints 
        (e.g., Budget < $10k).

    **VISUALIZATION 6: THE OPTIMIZATION ENGINE âš™ï¸**
    *Caption: Finding the perfect balance between profit and cost.*

    ğŸ“Š Historical Data (Sales, Spend, Price)
          â¬‡ï¸
    ğŸ¤– Digital Twin Model (y = mx + b)
       "I can predict Sales if you give me Spend & Price"
          â¬‡ï¸
    ğŸ¯ Objective: MAXIMIZE Profit ğŸ’°
    â›” Constraints: Budget < $10,000
          â¬‡ï¸
    ğŸ§® SOLVER ALGORITHM (Iterates inputs...)
       â”œâ”€â”€ Try 1: Spend $5k â¡ï¸ Profit $8k
       â”œâ”€â”€ Try 2: Spend $9k â¡ï¸ Profit $12k
       â””â”€â”€ Try 3: Spend $15k ğŸš« (Over Budget!)
          â¬‡ï¸
    âœ… OPTIMAL SOLUTION: "Spend exactly $9,999"

--------------------------------------------------------------------------------
7. ANOMALY DETECTION (Unsupervised Learning)
--------------------------------------------------------------------------------
*   **Algorithm**: **Isolation Forest**.
*   **Concept**: Anomalies are "few and different".
*   **How it works**:
    *   The algorithm builds an ensemble of random decision trees.
    *   At each node, it randomly selects a feature and a split value.
    *   **Normal points** are clustered together and require many splits to isolate.
    *   **Anomalies** are far apart and are isolated very quickly (short path length 
        from root to leaf).
*   **Scoring**: The average path length across all trees determines the anomaly score. 
    Shorter paths = Higher Anomaly Score.
*   **Contamination**: A hyperparameter defining the expected proportion of outliers 
    in the dataset (e.g., 0.05 or 5%).

    **VISUALIZATION 7: ISOLATION FOREST ğŸŒ²**
    *Caption: Detecting outliers by trying to isolate points.*

    ğŸŒ³ RANDOM FOREST (Decision Trees)
       â”œâ”€â”€ Point A (Normal Data):
       â”‚   Needs 10 random splits to isolate ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿
       â”‚   (Deep in the tree = "Normal" ğŸŸ¢)
       â”‚
       â””â”€â”€ Point B (Anomaly):
           Isolated in just 2 splits! âœ‚ï¸âœ‚ï¸
           (Shallow in the tree = "Anomaly" ğŸ”´)

    ğŸ“‰ RESULT:
       Point A Score: 0.2 (Safe)
       Point B Score: 0.9 (ALERT!)

--------------------------------------------------------------------------------
8. DATA GOVERNANCE & QUALITY
--------------------------------------------------------------------------------
*   **Concept**: Automated gates that stop bad data before it enters the system.

    **VISUALIZATION 8: THE QUALITY GATE ğŸš§**
    *Caption: How the pipeline protects the warehouse from bad data.*

    ğŸ“‚ New File (Sales.csv)
          â¬‡ï¸
    ğŸ›‘ QUALITY GATE (Rules Engine)
       â”œâ”€â”€ Rule 1: Sales > 0?      âœ… PASS
       â”œâ”€â”€ Rule 2: Valid Region?   âŒ FAIL (Found "Nrth")
       â””â”€â”€ Rule 3: No Duplicates?  âœ… PASS
          â¬‡ï¸
    ğŸš¨ ACTION: BLOCK PIPELINE
       (Log Error â¡ï¸ Alert Steward â¡ï¸ Halt Load)

--------------------------------------------------------------------------------
9. AUTOMATED ENRICHMENT
--------------------------------------------------------------------------------
*   **Concept**: Filling in missing data automatically using lookup tables.

    **VISUALIZATION 9: THE ENRICHMENT JOIN ğŸ”—**
    *Caption: Self-healing data by filling gaps.*

    ğŸ“„ Raw Data (Staging)
       [ SKU: "A-123" | Category: NULL âŒ ]
          â¬‡ï¸
    ğŸ”— ENRICHMENT ENGINE (Joins with Master Data)
       [ Lookup: "A-123" = "Electronics" ]
          â¬‡ï¸
    âœ¨ Enriched Data
       [ SKU: "A-123" | Category: "Electronics" âœ… ]

--------------------------------------------------------------------------------
10. THE FULL MODERN DATA STACK
--------------------------------------------------------------------------------
*   **Concept**: The end-to-end flow of the entire solution.

    **VISUALIZATION 10: ARCHITECTURE OVERVIEW ğŸ—ï¸**
    *Caption: From raw files to AI insights.*

    ğŸŒ SOURCES         âš™ï¸ INGESTION         ğŸ›¢ï¸ WAREHOUSE         ğŸ§  AI HUB
    (Files, API)      (Dagster ELT)        (SQL Server)         (Streamlit)
       ğŸ“„ ğŸ“„              ğŸ”„ ğŸ§¹                ğŸ’¾ ğŸ“Š                ğŸ¤– ğŸ’¬
    [Raw Data]  â¡ï¸  [Clean & Load]  â¡ï¸  [Store & Model]  â¡ï¸  [Visualize & Predict]
